#!/usr/bin/env python
# coding: utf-8

# # Customer Segmentation Analysis

# ## Overview
# This notebook demonstrates how to perform customer segmentation using K-Means clustering.
# Steps:
# 1. Import libraries
# 2. Load and explore data
# 3. Data preprocessing
# 4. K-Means clustering
# 5. Analysis and visualization of clusters

# ---
# ## 1. Import Libraries

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.cluster import KMeans
from scripts.preprocessing import load_data, clean_data, scale_features

# Set plotting style
sns.set(style="whitegrid")

# ---
# ## 2. Load Data

# Replace 'data/customer_data.csv' with your actual path if needed.
df = load_data('data/customer_data.csv')
print("Data loaded. Shape:", df.shape)

# Preview the first few rows
df.head()

# ---
# ## 3. Data Cleaning

# Perform basic data cleaning (handle missing values, duplicates, etc.)
df_cleaned = clean_data(df)
print("\nAfter cleaning:")
print(df_cleaned.info())

# Check for duplicates
duplicates = df_cleaned.duplicated().sum()
print(f"\nNumber of duplicate rows: {duplicates}")

# ---
# ## 4. Exploratory Data Analysis (EDA)

# Basic descriptive statistics
df_cleaned.describe()

# Pairplot to visualize potential clusters in Age vs. Annual Income vs. Spending Score
sns.pairplot(df_cleaned, vars=["Age", "AnnualIncome", "SpendingScore"], hue="Gender")
plt.show()

# Distribution of Spending Scores
plt.figure(figsize=(8,4))
sns.histplot(df_cleaned['SpendingScore'], kde=True, color='blue')
plt.title("Distribution of Spending Score")
plt.show()

# ---
# ## 5. Feature Scaling
# For clustering, scaling or normalization can help if feature scales vary significantly.

# Choose columns to scale (excluding CustomerID, Gender, etc.)
columns_to_scale = ["Age", "AnnualIncome", "SpendingScore"]
df_scaled = scale_features(df_cleaned, columns=columns_to_scale)

# Sanity check
df_scaled.head()

# ---
# ## 6. Finding Optimal Number of Clusters (Elbow Method)

X = df_scaled[columns_to_scale].values

inertia_values = []
cluster_range = range(1, 11)

for k in cluster_range:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X)
    inertia_values.append(kmeans.inertia_)

plt.figure(figsize=(8,4))
plt.plot(cluster_range, inertia_values, marker='o')
plt.title("Elbow Method")
plt.xlabel("Number of clusters (k)")
plt.ylabel("Inertia")
plt.show()

# From the elbow plot, we choose a k where the curve starts to flatten.
# Let's assume k=3 for demonstration.

# ---
# ## 7. Apply K-Means Clustering

k = 3
kmeans = KMeans(n_clusters=k, random_state=42)
df_scaled['Cluster'] = kmeans.fit_predict(X)

# ---
# ## 8. Visualize and Analyze Clusters

plt.figure(figsize=(8,6))
sns.scatterplot(x=df_scaled["AnnualIncome"], y=df_scaled["SpendingScore"],
                hue=df_scaled["Cluster"], palette="Set2")
plt.title("Customer Segments (K-Means Clustering)")
plt.show()

# Join cluster labels back to original DataFrame to see actual customer details
df_result = pd.concat([df_cleaned.reset_index(drop=True), 
                       df_scaled['Cluster'].reset_index(drop=True)], axis=1)

# Show sample results
df_result.head()

# ---
# ## 9. Cluster Profiles
# Let's group by cluster and observe mean values for key features.

cluster_profile = df_result.groupby('Cluster')[["Age", "AnnualIncome", "SpendingScore"]].mean()
print("\nCluster Profile (Mean Values):\n", cluster_profile)

# ---
# ## 10. Insights
# - Cluster 0: ...
# - Cluster 1: ...
# - Cluster 2: ...
#
# You can derive business insights here:
#  - Which clusters show high spending vs. low spending?
#  - Which clusters might need targeted marketing campaigns?

# ---
# ## 11. Next Steps
# 1. Experiment with different clustering algorithms (DBSCAN, Hierarchical, etc.)
# 2. Incorporate more features (e.g., transaction frequency, recency).
# 3. Perform advanced feature engineering.

# End of Notebook
